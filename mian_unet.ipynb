{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnMyvuzAVqXOgCoKd5IYzh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayshaashra/learn-Coding/blob/main/mian_unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cSU5a4TPRj2v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import skimage\n",
        "\n",
        "from skimage.util import view_as_windows\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurations and hyperparameters\n",
        "config = {\n",
        "    'base_dir': 'D:/Working/data/LEVIR-CD1',\n",
        "    'patch_size': 256,\n",
        "    'batch_size': 32,\n",
        "    'epochs': 100,\n",
        "    'augment_data': True\n",
        "}"
      ],
      "metadata": {
        "id": "JICGHhcIRs4x"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Efficient patch extraction function using skimage\n",
        "def cut_into_patches(image_path, patch_size=256):\n",
        "    image = Image.open(image_path).convert(\"L\")\n",
        "    image = np.array(image) / 255.0  # Normalize while converting to an array\n",
        "    window_shape = (patch_size, patch_size)\n",
        "    patches = view_as_windows(image, window_shape, step=patch_size)\n",
        "    patches = patches.reshape(-1, patch_size, patch_size)\n",
        "    return patches\n"
      ],
      "metadata": {
        "id": "aP5IoWgARyHw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generator with optional augmentation\n",
        "def data_generator(image_pairs, labels, batch_size, patch_size, augment=False):\n",
        "    while True:\n",
        "        np.random.shuffle(image_pairs)  # Shuffle at each epoch\n",
        "        for start in range(0, len(image_pairs), batch_size):\n",
        "            end = start + batch_size\n",
        "            X_batch, Y_batch = [], []\n",
        "            for (image_a_path, image_b_path), label_path in image_pairs[start:end]:\n",
        "                try:\n",
        "                    image_a_patches = cut_into_patches(image_a_path, patch_size)\n",
        "                    image_b_patches = cut_into_patches(image_b_path, patch_size)\n",
        "                    label_patches = cut_into_patches(label_path, patch_size)\n",
        "\n",
        "                    if augment:\n",
        "                        # Placeholder for actual augmentation logic\n",
        "                        pass\n",
        "\n",
        "                    for patch_a, patch_b, patch_label in zip(image_a_patches, image_b_patches, label_patches):\n",
        "                        X_batch.append(np.stack([patch_a, patch_b], axis=-1))\n",
        "                        Y_batch.append(to_categorical(patch_label, num_classes=2).reshape(patch_size, patch_size, 2))\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Failed to process data: {e}\")\n",
        "                    continue\n",
        "\n",
        "            yield np.array(X_batch), np.array(Y_batch)"
      ],
      "metadata": {
        "id": "S8sc1nrURz9g"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "def load_dataset(base_dir, subset):\n",
        "    dir_path = os.path.join(base_dir, subset)\n",
        "    a_dir = os.path.join(dir_path, 'A')\n",
        "    b_dir = os.path.join(dir_path, 'B')\n",
        "    label_dir = os.path.join(dir_path, 'label')\n",
        "    a_images = sorted([f for f in os.listdir(a_dir) if f.endswith('.PNG')])\n",
        "    b_images = sorted([f for f in os.listdir(b_dir) if f.endswith('.PNG')])\n",
        "    labels = sorted([f for f in os.listdir(label_dir) if f.endswith('.PNG')])\n",
        "    image_pairs, label_paths = [], []\n",
        "    for a, b, label in zip(a_images, b_images, labels):\n",
        "        if a == b == label:\n",
        "            image_pairs.append((os.path.join(a_dir, a), os.path.join(b_dir, b)))\n",
        "            label_paths.append(os.path.join(label_dir, label))\n",
        "    return image_pairs, label_paths"
      ],
      "metadata": {
        "id": "7iKluZ7WSZgB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function to run the model training\n",
        "if __name__ == \"__main__\":\n",
        "    train_pairs, train_labels = load_dataset(config['base_dir'], 'train')\n",
        "    val_pairs, val_labels = load_dataset(config['base_dir'], 'val')\n",
        "\n",
        "    train_generator = data_generator(train_pairs, train_labels, config['batch_size'], config['patch_size'], config['augment_data'])\n",
        "    val_generator = data_generator(val_pairs, val_labels, config['batch_size'], config['patch_size'])\n",
        "\n",
        "    model = build_unet((config['patch_size'], config['patch_size'], 2))\n",
        "    checkpoint = ModelCheckpoint('model_best.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
        "\n",
        "    model.fit(train_generator,\n",
        "              steps_per_epoch=len(train_pairs) // config['batch_size'],\n",
        "              epochs=config['epochs'],\n",
        "              validation_data=val_generator,\n",
        "              validation_steps=len(val_pairs) // config['batch_size'],\n",
        "              callbacks=[checkpoint, early_stop])"
      ],
      "metadata": {
        "id": "83lg7xiKSeEa",
        "outputId": "e7368942-1e2e-4415-f195-e7eeafcd98bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'D:/Working/data/LEVIR-CD1/train/A'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-9823b05ed1d8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Main function to run the model training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mval_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-fc3528f6a803>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(base_dir, subset)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mb_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'B'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlabel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0ma_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.PNG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mb_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.PNG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.PNG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/Working/data/LEVIR-CD1/train/A'"
          ]
        }
      ]
    }
  ]
}